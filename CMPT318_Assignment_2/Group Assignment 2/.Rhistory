library(tidyr)
library(dplyr)
library(ggplot2)
library(ggcorrplot)
library(lubridate)
library(forecast)
library(zoo)
library("depmixS4")
gc()
library(tidyr)
library(dplyr)
library(ggplot2)
library(ggbiplot)
library(ggcorrplot)
library(lubridate)
library(tidyr)
library(dplyr)
library(ggplot2)
library(ggbiplot)
library(ggcorrplot)
library(lubridate)
library(forecast)
library(zoo)
library("depmixS4")
load_data <- function() {
# Get the data from the data set
data <- read.table("TermProjectData.txt", header = TRUE)
# Convert the column Date to Date objects (so that we can extract)
data$Date = as.POSIXlt(data$Date, format = "%d/%m/%Y")
# Extract data from all complete weeks
df <- data[data$Date >= as.POSIXlt("2006-12-11") & data$Date <= as.POSIXlt("2009-11-30"),]
# Parse column 2 into separate columns
dfsplit <- strsplit(df[,2], ",") # split the data
df2 <- data.frame(dfsplit) # Put the data into a df
df2 <- as.data.frame(t(df2)) #transpose to turn rows into cols
rm(dfsplit)
# Reindexing with help from James Comment:
# https://stackoverflow.com/questions/7567790/change-the-index-number-of-a-dataframe
rownames(df2) <- 1:nrow(df2)
df2 <- subset(df2, select = -V1) # Drop all columns we dont need
df2$V2 <- substr(df2$V2, 2, 9) # Drop the quotations from "time" column
# Rename the column names
colnames(df2) <- c("Time", "Global_active_power", "Global_reactive_power", "Voltage", "Global_intensity", "Sub_metering_1", "Sub_metering_2", "Sub_metering_3")
# Merge Date and Time into one column
df$Date <- as.POSIXlt(paste(df$Date, df2$Time), format = "%Y-%m-%d %H:%M:%S")
# Drop the columns that we don't want anymore
df <- subset (df, select = Date)
df$Time <- df2$Time
df2 <- subset (df2, select = -Time)
# Merge df and df2 and deselect all we dont need
df <- cbind(df, df2)
# Convert from char to numeric values
df[,3:9] <- sapply(df[,3:9], as.numeric)
return (df)
}
perform_PCA <- function(df) {
df = na.omit(df)
df.pca <- prcomp(df[, 3:9], center = TRUE, scale. = TRUE, retx = TRUE)
summary(df.pca)
head(df.pca$x)
# How many components should we use?
return (df.pca)
}
split_data <- function(data) {
set.seed(123)
sample <- sample(c(rep(0, 0.7 * nrow(data)), rep(1, 0.3 * nrow(data))))
return (sample)
}
# main
setwd("/Users/MichaelKuby/Documents/GitHub/CMPT318_CyberSecurity/Term Project")
df <- load_data()
# Use PCA to train HMM?
use_pca <- TRUE
# feature engineering
df.pca <- perform_PCA(df)
# Use PC1, PC2, PC3 to explain 68% of the variation in the data
data = df.pca$x
data = subset(data, select = c(PC1, PC2, PC3))
data <- as.data.frame(data)
View(data)
# add in the time
df2 <-na.omit(df)
data <- merge(df2, data)
View(df2)
# add in the time
data$Date <- na.omit(df$Date)
# Use PC1, PC2, PC3 to explain 68% of the variation in the data
data = df.pca$x
data = subset(data, select = c(PC1, PC2, PC3))
data <- as.data.frame(data)
# add in the time
df2 <- na.omit(df)
data$Date <- df2$Date
data$Time <- df2$Time
View(data)
# Split the data into train and test
sample <- sample(c(rep(0, 0.7 * nrow(data)), rep(1, 0.3 * nrow(data))))
table(sample)
train <- data[sample == 0, ]
test <- data[sample == 1, ]
dim(test)
dim(train)
average_week <- function(data, colname = "Global_intensity") {
df <- subset(data, select = c(Date, Time))
df2 <- subset(data, select = c(colname))
df <- cbind(df, df2)
df$Day = weekdays(as.Date(df$Date))
# n weeks, ms samples and msn number of samples returned for the week
n = 52
nw = 1
msn = 10080
ms = 10
df_ma <- data.frame(Date = data$Date,
Num_week=strftime(data$Date, format = "%V"),
Day = strftime(data$Date, format = "%A"),
Time = strftime(data$Date, format = "%T"),
Moving_average=data[colname])
df_ma$Num_week <- sub("^0", "", df_ma$Num_week)
# breakdown the average calculations per week
df_ma$Moving_average <- ma(data[colname], ms, centre = TRUE)
# create average week
average_week <- df_ma %>% group_by(Day, Time)
average_week <- average_week %>% summarise(
Moving_average = mean(Moving_average, na.rm = TRUE)
)
# manually reorder average_week
order <- c("Monday", "Tuesday", "Wednesday", "Thursday","Friday", "Saturday", "Sunday")
average_week = average_week %>%
mutate(Day =  factor(Day, levels = order)) %>%
arrange(Day)
average_week$Date <- df[1:10080, "Date"]
return (average_week)
}
# compute the average week for a given feature (column)
feature_1 <- "PC1"
average_week_PC1 <- average_week(df_scaled, feature_1)
average_week_PC1 <- average_week(data, feature_1)
data$Day <- weekdays(df2$Date)
View(data)
# compute the average week for a given feature (column)
feature_1 <- "PC1"
average_week_PC1 <- average_week(data, feature_1)
debug(average_week)
average_week_PC1 <- average_week(data, feature_1)
library(tidyr)
library(dplyr)
library(ggplot2)
library(ggcorrplot)
library(lubridate)
library(forecast)
library(zoo)
library("depmixS4")
average_week_PC1 <- average_week(data, feature_1)
average_week_PC1 <- average_week(data, feature_1)
average_week_PC1 <- average_week(data, feature_1)
View(df)
View(df)
View(df_ma)
View(df_ma)
View(df_ma)
View(average_week)
View(average_week)
# create average week
average_week <- df_ma %>% group_by(Day, Time)
?summarise
source("~/Documents/GitHub/CMPT318_CyberSecurity/CMPT318_Assignment_3/Group Assignment 3/CMPT318_Assignment_3.R", echo=TRUE)
library(dplyr)
average_week_PC1 <- average_week(data, feature_1)
